"""
Detector de vÃ­deos duplicados.
"""

import hashlib
from pathlib import Path
from typing import Dict, List

from ..common.paths import obter_pastas_entrada_saida
from ..common.progress import ProgressBar


class DetectorDuplicatasVideos:
    """
    Classe para detectar vÃ­deos duplicados.
    """

    EXTENSOES_VALIDAS = {".mp4", ".m4v", ".mov", ".webm", ".avi", ".mkv"}

    def __init__(
        self,
        pasta_origem: Path = None,
        remover_automaticamente: bool = False,
    ):
        """
        Inicializa o detector.

        Args:
            pasta_origem: Pasta com vÃ­deos para verificar (None = padrÃ£o).
            remover_automaticamente: Se True, remove duplicatas automaticamente.
        """
        if pasta_origem is None:
            entrada, _ = obter_pastas_entrada_saida("videos")
            self.pasta_origem = entrada
        else:
            self.pasta_origem = pasta_origem

        self.remover_automaticamente = remover_automaticamente

    def _calcular_hash_arquivo(self, caminho: Path) -> str:
        """
        Calcula hash MD5 do arquivo (amostra para vÃ­deos grandes).

        Args:
            caminho: Caminho do arquivo.

        Returns:
            str: Hash MD5.
        """
        hash_md5 = hashlib.md5()
        try:
            tamanho = caminho.stat().st_size
            # Para vÃ­deos grandes, usa amostra (primeiros 10MB + Ãºltimos 10MB)
            with open(caminho, "rb") as f:
                # Primeiros 10MB
                chunk_size = 10 * 1024 * 1024
                chunk = f.read(chunk_size)
                hash_md5.update(chunk)

                # Ãšltimos 10MB se o arquivo for grande
                if tamanho > chunk_size * 2:
                    f.seek(tamanho - chunk_size)
                    chunk = f.read(chunk_size)
                    hash_md5.update(chunk)

            return hash_md5.hexdigest()
        except Exception:
            return ""

    def processar(self) -> dict:
        """
        Processa e detecta duplicatas.

        Returns:
            dict: EstatÃ­sticas do processamento.
        """
        pasta_origem = Path(self.pasta_origem).resolve()

        if not pasta_origem.exists():
            print(f"âŒ Erro: Pasta nÃ£o encontrada: {pasta_origem}")
            return {"duplicatas": 0, "removidos": 0}

        arquivos = [
            f
            for f in pasta_origem.iterdir()
            if f.is_file() and f.suffix.lower() in self.EXTENSOES_VALIDAS
        ]

        if len(arquivos) < 2:
            print("â„¹ï¸  Ã‰ necessÃ¡rio pelo menos 2 vÃ­deos para detectar duplicatas.")
            return {"duplicatas": 0, "removidos": 0}

        print(f"ğŸš€ Analisando {len(arquivos)} vÃ­deo(s) para duplicatas...")
        print("   (Usando amostra de arquivos grandes para velocidade)")
        print("-" * 60)

        # Mapa de hash -> lista de arquivos
        hash_map: Dict[str, List[Path]] = {}

        # Calcula hashes
        with ProgressBar(
            total=len(arquivos), desc="Calculando hashes", unit="vÃ­deo"
        ).context() as pbar:
            for arquivo in arquivos:
                hash_val = self._calcular_hash_arquivo(arquivo)
                if hash_val:
                    if hash_val not in hash_map:
                        hash_map[hash_val] = []
                    hash_map[hash_val].append(arquivo)
                pbar.update(1)

        # Encontra duplicatas
        duplicatas_encontradas = 0
        removidos = 0

        print("\nğŸ“Š Analisando resultados...")
        print("-" * 60)

        for hash_val, arquivos_duplicados in hash_map.items():
            if len(arquivos_duplicados) > 1:
                duplicatas_encontradas += len(arquivos_duplicados) - 1

                # MantÃ©m o primeiro, remove os outros
                original = arquivos_duplicados[0]
                duplicados = arquivos_duplicados[1:]

                print(f"\nğŸ” Duplicatas encontradas ({len(arquivos_duplicados)} arquivos):")
                print(f"   âœ… Mantido: {original.name} ({original.stat().st_size / (1024*1024):.2f} MB)")

                for dup in duplicados:
                    tamanho_mb = dup.stat().st_size / (1024 * 1024)
                    print(f"   âŒ Duplicata: {dup.name} ({tamanho_mb:.2f} MB)")

                    if self.remover_automaticamente:
                        try:
                            dup.unlink()
                            print(f"      ğŸ—‘ï¸  Removido")
                            removidos += 1
                        except Exception as e:
                            print(f"      âš ï¸  Erro ao remover: {e}")

        print("\n" + "=" * 60)
        print("ğŸ“Š RESUMO")
        print("-" * 60)
        print(f"ğŸ” Duplicatas encontradas: {duplicatas_encontradas}")
        if self.remover_automaticamente:
            print(f"ğŸ—‘ï¸  Arquivos removidos: {removidos}")
        else:
            print("ğŸ’¡ Use --remover para remover duplicatas automaticamente")
        print("-" * 60)

        return {"duplicatas": duplicatas_encontradas, "removidos": removidos}

